# LLM Hub

**LLM Hub** is a lightweight, open-source LLM API gateway that routes requests across multiple AI providers and API keys with quota-aware fallback, user authentication, and a built-in dashboard.

The project is designed for developers who work with **multiple free or limited API keys** and want a single unified endpoint with automatic routing, failover, and observability.

---

## âœ¨ Features

- Unified `/v1/chat` API (OpenAI-style)
- Multi-provider support (OpenAI, Gemini, Claude, etc.)
- Multiple API keys per provider
- Quota-aware routing & automatic fallback
- Rate-limit & cooldown handling
- Web dashboard (React)
- User accounts (username/email + password)
- Secure API key management via dashboard
- Admin monitoring & routing logs
- MIT licensed, public & self-hostable

---

## ğŸ§  Use Cases

- Pool multiple **free-tier API keys**
- Automatically switch when a key hits quota
- Compare or fallback between providers
- Internal AI gateway for teams
- Experimentation without hardcoding keys
- LLM infrastructure layer for games, tools, or products

---

## ğŸ—ï¸ Architecture Overview

```
Client / App / Game
        â†“
      LLM Hub
        â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Provider Router             â”‚
â”‚  - OpenAI (multiple keys)   â”‚
â”‚  - Gemini (multiple keys)   â”‚
â”‚  - Claude (multiple keys)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
   Quota & Rate Tracker
        â†“
   SQLite / Redis / Postgres
```

- **Backend:** Python + FastAPI
- **Frontend:** React (Next.js)
- **Storage:** SQLite (dev), Redis/Postgres (prod)

---

## ğŸ“ Repository Structure

```
llm-hub/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py          # FastAPI entry
â”‚   â”‚   â”œâ”€â”€ router.py        # Routing & fallback logic
â”‚   â”‚   â”œâ”€â”€ providers/       # Provider adapters
â”‚   â”‚   â”œâ”€â”€ quota/           # Quota & rate tracking
â”‚   â”‚   â”œâ”€â”€ admin/           # Admin & dashboard APIs
â”‚   â”‚   â””â”€â”€ auth/            # User auth & sessions
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ app/                 # React / Next.js app
â”‚   â”œâ”€â”€ components/
â”‚   â””â”€â”€ lib/
â”‚
â”œâ”€â”€ docker/
â”œâ”€â”€ docs/
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## ğŸŒ Public API

### Chat endpoint

```
POST /v1/chat
```

Request body:

```
{
  "model": "smart",
  "messages": [
    { "role": "user", "content": "Hello" }
  ]
}
```

### Logical model routing

- `smart` â†’ high-quality model with fallback
- `fast` â†’ low-latency model
- `cheap` â†’ low-cost model
- `any` â†’ first available provider with quota

Clients do **not** need to know:

- Which provider is used
- Which API key is active
- When fallback happens

---

## ğŸ“Š Dashboard

The dashboard is a **core part of llm-hub**, not an optional add-on.

### Dashboard capabilities

- User registration & login (account + password)
- Add / remove / disable API keys
- Assign API keys to providers
- View quota usage per key
- Routing & fallback logs
- Provider health & latency
- Admin-only controls

---

## ğŸ” Authentication & Security

- Username/email + password authentication
- Passwords hashed (bcrypt or argon2)
- API keys encrypted at rest
- API keys never exposed to clients
- Keys masked in UI (example: `sk-****1234`)
- Dashboard access requires authentication

---

## ğŸ“„ License

This project is licensed under the **MIT License**.
